{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bab74eb8",
   "metadata": {},
   "source": [
    "# Data Import\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This notebook shows how to import data into a DuckDB database. It uses the `duckdb` Python package to connect to a DuckDB database and import data from various formats, including CSV, JSON, DataFrame, parquet, GeoJSON, Shapefile, GeoParquet, and more.\n",
    "\n",
    "## Datasets\n",
    "\n",
    "The following datasets are used in this notebook. You don't need to download them, they can be accessed directly from the notebook.\n",
    "\n",
    "- [cities.csv](https://open.gishub.org/data/duckdb/cities.csv)\n",
    "- [countries.csv](https://open.gishub.org/data/duckdb/countries.csv)\n",
    "\n",
    "## Installation\n",
    "\n",
    "Uncomment the following cell to install the required packages if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1e120c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install duckdb leafmap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9bdef7",
   "metadata": {},
   "source": [
    "## Library Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b32868",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import leafmap\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a393dfa",
   "metadata": {},
   "source": [
    "## Installing Extensions\n",
    "\n",
    "DuckDBâ€™s Python API provides functions for installing and loading extensions, which perform the equivalent operations to running the `INSTALL` and `LOAD` SQL commands, respectively. An example that installs and loads the [httpfs extension](https://duckdb.org/docs/extensions/httpfs) looks like follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c14684a",
   "metadata": {},
   "outputs": [],
   "source": [
    "con = duckdb.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f5fbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.install_extension(\"httpfs\")\n",
    "con.load_extension(\"httpfs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec021e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.install_extension(\"spatial\")\n",
    "con.load_extension(\"spatial\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b3fe21",
   "metadata": {},
   "source": [
    "## Downloading Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d0757a",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://open.gishub.org/data/duckdb/cities.zip\"\n",
    "leafmap.download_file(url, unzip=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c5f541",
   "metadata": {},
   "source": [
    "## CSV Files\n",
    "\n",
    "CSV files can be read using the `read_csv` function, called either from within Python or directly from within SQL. By default, the `read_csv` function attempts to auto-detect the CSV settings by sampling from the provided file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cd2dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read from a file using fully auto-detected settings\n",
    "con.read_csv('cities.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ac9d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify options on how the CSV is formatted internally\n",
    "con.read_csv('cities.csv', header=True, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c2924c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the (experimental) parallel CSV reader\n",
    "con.read_csv('cities.csv', parallel=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68476bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directly read a CSV file from within SQL\n",
    "con.sql(\"SELECT * FROM 'cities.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b5ccb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call read_csv from within SQL\n",
    "con.sql(\"SELECT * FROM read_csv_auto('cities.csv')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38337a5",
   "metadata": {},
   "source": [
    "## JSON Files\n",
    "\n",
    "JSON files can be read using the `read_json` function, called either from within Python or directly from within SQL. By default, the `read_json` function will automatically detect if a file contains newline-delimited JSON or regular JSON, and will detect the schema of the objects stored within the JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6686b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read from a single JSON file\n",
    "con.read_json('cities.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb0adfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directly read a JSON file from within SQL\n",
    "con.sql(\"SELECT * FROM 'cities.json'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d6b64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call read_json from within SQL\n",
    "con.sql(\"SELECT * FROM read_json_auto('cities.json')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226a6878",
   "metadata": {},
   "source": [
    "## DataFrames\n",
    "\n",
    "DuckDB is automatically able to query a Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2642cf3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('cities.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e80c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql('SELECT * FROM df').fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d373c3c5",
   "metadata": {},
   "source": [
    "## Parquet Files\n",
    "\n",
    "Parquet files can be read using the `read_parquet` function, called either from within Python or directly from within SQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2ecc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read from a single Parquet file\n",
    "con.read_parquet('cities.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4c9cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directly read a Parquet file from within SQL\n",
    "con.sql(\"SELECT * FROM 'cities.parquet'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab7e138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call read_parquet from within SQL\n",
    "con.sql(\"SELECT * FROM read_parquet('cities.parquet')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320fa682",
   "metadata": {},
   "source": [
    "## GeoJSON Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a4dde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql('SELECT * FROM ST_Drivers()')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a7395f",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\"SELECT * FROM ST_Read('cities.geojson')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be367924",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\"FROM ST_Read('cities.geojson')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cdb99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\"CREATE TABLE cities AS SELECT * FROM ST_Read('cities.geojson')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a047577",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.table('cities')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0c43b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\"SELECT * FROM cities\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7d9c05",
   "metadata": {},
   "source": [
    "## Shapefiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1733145",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\"SELECT * FROM ST_Read('cities.shp')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db259033",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\"FROM ST_Read('cities.shp')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326c56ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\n",
    "    \"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS cities2 AS \n",
    "        SELECT * FROM ST_Read('cities.shp')\n",
    "        \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c988f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.table('cities2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a008e1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql('SELECT * FROM cities2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cecb19d0",
   "metadata": {},
   "source": [
    "## GeoParquet Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f255e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\"SELECT * FROM 'cities.parquet'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c548f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\n",
    "    \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS cities3 AS\n",
    "SELECT * EXCLUDE geometry, ST_GeomFromWKB(geometry) \n",
    "AS geometry FROM 'cities.parquet'\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f773b23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.table('cities3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb76c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\n",
    "    \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS country AS\n",
    "SELECT * EXCLUDE geometry, ST_GeomFromWKB(geometry) FROM\n",
    "        's3://us-west-2.opendata.source.coop/google-research-open-buildings/v2/geoparquet-admin1/country=SSD/*.parquet'\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466a2843",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.table('country')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bc1bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql('SELECT COUNT(*) FROM country')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57d6213",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- [DuckDB Data Ingestion](https://duckdb.org/docs/api/python/data_ingestion)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.13,
    "jupytext_version": "1.15.2"
   }
  },
  "kernelspec": {
   "display_name": "geo",
   "language": "python",
   "name": "python3"
  },
  "source_map": [
   12,
   31,
   33,
   37,
   41,
   47,
   51,
   56,
   59,
   63,
   66,
   72,
   77,
   82,
   87,
   92,
   95,
   101,
   106,
   111,
   114,
   120,
   125,
   127,
   133,
   138,
   143,
   146,
   150,
   154,
   158,
   162,
   166,
   170,
   172,
   176,
   180,
   184,
   193,
   197,
   199,
   203,
   207,
   217,
   221,
   231,
   235,
   237
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}